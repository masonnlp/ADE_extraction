{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8e229-473c-42a2-8eb9-58d4de22045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def import_data(importDirectory, train_or_valid, spacy_tokenizer_name):\n",
    "    export_list = []\n",
    "    for file in os.listdir(importDirectory):\n",
    "        filenameArr = file.split('.')\n",
    "        filenameArr2 = file.split('_')\n",
    "        if(len(filenameArr) > 1):\n",
    "            if(filenameArr2[0] == train_or_valid):\n",
    "                if(spacy_tokenizer_name in file):\n",
    "                    if(filenameArr[1] == 'pkl'):\n",
    "                        with open(importDirectory+'/'+file, 'rb') as f:\n",
    "                            data = pickle.load(f)\n",
    "                            f.close()\n",
    "                            export_list.append(data)\n",
    "    return(export_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3d2fe-24e6-4495-9928-b724bc95508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_path = #should equal the path to the folder containing the output of BRAT_Parser\n",
    "#Data is a list with a length equal to the amount of folders that were iterated through \n",
    "#data[n] is a list of length x. X is the number of files presnet in the nth folder. \n",
    "#data[n][x] is a dictionary, with keys 'ADE_strings', 'noADE_strings', 'num_Multi_Token_ADE_Relatons\n",
    "\n",
    "\n",
    "#Will work with data via Hugging Face Datasets library\n",
    "#Should be a dataset dict: {\"train\": [\"string\", \"label\", \"idx\"], \"verification\":[\"string\", \"label\", \"idx\"], \"test\":[...\n",
    "#First, cast it to a pandas df of shape [\"label\"][\"string\" ....] \n",
    "def load_data(import_path, train_or_valid, spacy_tokenizer_name):\n",
    "    data = import_data(import_path, train_or_valid, spacy_tokenizer_name)\n",
    "    \n",
    "    dataset = pd.DataFrame({})\n",
    "    ADE_Strings = [] \n",
    "    noADE_Strings = []\n",
    "    \n",
    " \n",
    "    for i in data:\n",
    "        for j in i[0]:\n",
    "            #temp = j[0]\n",
    "            for k in j.get('ADE_strings'):\n",
    "                ADE_Strings.append(k.get('string'))\n",
    "            for k in j.get('noADE_strings'):\n",
    "                noADE_Strings.append(k.get('string'))\n",
    "    dataset['string'] = ADE_Strings + noADE_Strings\n",
    "    #Set to 1 because they are ADE\n",
    "    dataset.loc[0:len(ADE_Strings)-1, ('label')] = 1\n",
    "    #Set rest to 0 because they are not ADE\n",
    "    dataset.loc[len(ADE_Strings):len(dataset['string']), ('label')] = 0\n",
    "    return(dataset)\n",
    "\n",
    "#note: train2/dev2 names represent files that only treat the Problem events in ADE tags as ADE sentences, not both Problem AND Drug\n",
    "\n",
    "train_dataframe = load_data(import_path, 'train3', \"en_core_sci_md\")\n",
    "train_dataframe['label'] = train_dataframe['label'].astype(int)\n",
    "\n",
    "valid_dataframe = load_data(import_path, 'test3', \"en_core_sci_md\")\n",
    "#Without this line, will result in dimesnioanl mismatch: https://discuss.huggingface.co/t/valueerror-target-size-torch-size-8-must-be-the-same-as-input-size-torch-size-8-8/12133/2\n",
    "valid_dataframe['label'] = valid_dataframe['label'].astype(int)\n",
    "\n",
    "\n",
    "train_dataframe.rename(columns={'string':'sentence'}, inplace=True)\n",
    "valid_dataframe.rename(columns={'string':'sentence'}, inplace=True)\n",
    "\n",
    "\n",
    "#print(type(train_dataframe['label'][0]))\n",
    "display(train_dataframe)\n",
    "display(valid_dataframe)\n",
    "\n",
    "print(\"Total length of train dataframe:\")\n",
    "print(len(train_dataframe))\n",
    "print(\"Length of class 1, ADE\")\n",
    "print(train_dataframe['label'].value_counts().get(1))\n",
    "print(\"Length of  class 2, noADE\")\n",
    "print(train_dataframe['label'].value_counts().get(0))\n",
    "\n",
    "\n",
    "print(\"Total length of dev dataframe:\")\n",
    "print(len(valid_dataframe))\n",
    "print(\"Length of class 1, ADE\")\n",
    "print(valid_dataframe['label'].value_counts().get(1))\n",
    "print(\"Length of  class 2, noADE\")\n",
    "print(valid_dataframe['label'].value_counts().get(0))\n",
    "\n",
    "print(\"\\n\\nADE Example\")\n",
    "print(train_dataframe.iloc[1, 0])\n",
    "print('--------')\n",
    "print(\"noADE Example\")\n",
    "print(train_dataframe.iloc[16244, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e42f2-4c80-49dd-a010-7bcf4caf33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "train_data = train_dataframe\n",
    "test_data = valid_dataframe\n",
    "\n",
    "# Extract features from text using TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['sentence'])\n",
    "X_test = vectorizer.transform(test_data['sentence'])\n",
    "\n",
    "# Get labels\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7099ab-9d8c-4400-996b-f68f2bcf62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = 10, balanced = default, f1 = .49\n",
    "# Initialize and train the SVM classifier\n",
    "svm_classifier = SVC(kernel='sigmoid', C=10, class_weight={0:1, 1:5})  # You can choose different kernels based on your data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "classification_report_result = classification_report(y_test, predictions, digits=3)\n",
    "\n",
    "print(\"SIGMOID\")\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc08566-ebd8-4276-baf8-36000a5975d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(data, path):\n",
    "    f = open(path+\".pkl\",'w')\n",
    "    f.close()\n",
    "    f = open(path+\".pkl\", \"wb\")\n",
    "    pickle.dump(data, f)\n",
    "    f.close()\n",
    "\n",
    "export_data({'predictions':predictions, 'ground_truth':y_test}, \"SVM_predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
